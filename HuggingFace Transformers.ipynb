{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b9e240",
   "metadata": {},
   "source": [
    "## HuggingFace Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aa1213",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a81e5f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "223ae95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!pip install -U \"torch>=2.2\" \"transformers>=4.42\" \"huggingface_hub>=0.23\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb647240",
   "metadata": {},
   "source": [
    "#### Creating a sentiment classifier pipleine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161d81f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tok = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "\n",
    "sentiment_classifier = pipeline(\n",
    "    task=\"text-classification\",   # same as sentiment-analysis\n",
    "    model=model,\n",
    "    tokenizer=tok,\n",
    "    framework=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfa993ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.8438990712165833}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_classifier(\"bro forgot violence can be the big funny\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ca75d1",
   "metadata": {},
   "source": [
    "#### Name Entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a3843ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Student\\.cache\\huggingface\\hub\\models--dslim--bert-base-NER. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", model = \"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64bd8754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': np.float32(0.9954881),\n",
       "  'index': 4,\n",
       "  'word': 'Anna',\n",
       "  'start': 12,\n",
       "  'end': 16},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': np.float32(0.99960667),\n",
       "  'index': 9,\n",
       "  'word': 'New',\n",
       "  'start': 34,\n",
       "  'end': 37},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': np.float32(0.9993955),\n",
       "  'index': 10,\n",
       "  'word': 'York',\n",
       "  'start': 38,\n",
       "  'end': 42},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': np.float32(0.9995803),\n",
       "  'index': 11,\n",
       "  'word': 'City',\n",
       "  'start': 43,\n",
       "  'end': 47},\n",
       " {'entity': 'B-ORG',\n",
       "  'score': np.float32(0.9957462),\n",
       "  'index': 13,\n",
       "  'word': 'Morgan',\n",
       "  'start': 52,\n",
       "  'end': 58},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': np.float32(0.9979346),\n",
       "  'index': 14,\n",
       "  'word': 'Stanley',\n",
       "  'start': 59,\n",
       "  'end': 66}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"Her name is Anna and she works in New York City for Morgan Stanley\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a793e0d",
   "metadata": {},
   "source": [
    "#### Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37e8d94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Student\\.cache\\huggingface\\hub\\models--facebook--bart-large-mnli. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "zeroshot_classifier = pipeline(\"zero-shot-classification\", model = \"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd62c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_to_classify = \"one day I will see the world\"\n",
    "candidate_labels = ['travel', 'cooking', 'dancing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d9a0f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'one day I will see the world',\n",
       " 'labels': ['travel', 'dancing', 'cooking'],\n",
       " 'scores': [0.9938650727272034, 0.0032737981528043747, 0.0028610387817025185]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshot_classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27f9d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_to_classify = \"I love this new smartphone, it's amazing!\"\n",
    "candidate_labels = ['technology', 'cooking', 'dancing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aac14c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': \"I love this new smartphone, it's amazing!\",\n",
       " 'labels': ['technology', 'dancing', 'cooking'],\n",
       " 'scores': [0.9925756454467773, 0.0044857775792479515, 0.0029386423993855715]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshot_classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "706f7190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998770952224731}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_classifier(sequence_to_classify))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eb1c44",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
